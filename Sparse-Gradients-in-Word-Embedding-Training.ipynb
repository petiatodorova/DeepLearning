{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b091f429-70fe-4aae-ac61-db8850b0a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632519a1-7d72-45c9-9e06-0e7450c0f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size and embedding dimension\n",
    "vocab_size = 20  # Small vocabulary\n",
    "embedding_dim = 5  # Embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f8d4b2-a139-47d6-844b-9381f73e4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca4df3e-ca9c-4bbc-b74d-aa586e2d0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple loss function and optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970bd53b-93da-4ced-a7b6-bef08393a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated input batch of word indices (sparse updates)\n",
    "word_indices = tf.constant([[1, 3, 7], [2, 5, 8]], dtype=tf.int32)  # Batch of word indices\n",
    "targets = tf.random.normal((2, 3, embedding_dim))  # Random target embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6532a7f4-9760-405c-91d5-9d4b9ff724cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.0070326328277588\n",
      "Sparse Gradient Example (only non-zero updates):\n",
      "Non-zero gradients: 30/100 parameters\n",
      "Gradients (truncated):\n",
      "[<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x000001961BD0A210>]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        embeddings = embedding_layer(word_indices)  # Get embeddings for the words in the batch\n",
    "        loss = loss_fn(targets, embeddings)  # Compute MSE loss with the target embeddings\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(loss, embedding_layer.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(gradients, embedding_layer.trainable_variables))\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}: Loss = {loss.numpy()}\")\n",
    "    \n",
    "    # Display gradient sparsity\n",
    "    print(\"Sparse Gradient Example (only non-zero updates):\")\n",
    "    non_zero_updates = tf.reduce_sum(tf.cast(tf.not_equal(gradients[0], 0), tf.int32)).numpy()\n",
    "    print(f\"Non-zero gradients: {non_zero_updates}/{vocab_size * embedding_dim} parameters\")\n",
    "    print(\"Gradients (truncated):\")\n",
    "    print(gradients[:10])  # Print gradients for the first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1b38d4-bcb3-424f-a21a-ebaa15ddb615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final embeddings (first 5 words):\n",
      "tf.Tensor(\n",
      "[[-0.04614676  0.00548912  0.0450556  -0.04679706  0.00980228]\n",
      " [ 0.04905393 -0.01446868  0.0105222   0.00238351  0.04675721]\n",
      " [-0.02414486 -0.03999238 -0.05066098  0.0208729   0.02861297]\n",
      " [ 0.03482476  0.02229689  0.04842939 -0.01246209 -0.02342523]\n",
      " [ 0.03767601 -0.0380299  -0.04815232 -0.02079639 -0.04310198]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Verify embeddings for untouched indices remain unchanged\n",
    "print(\"\\nFinal embeddings (first 5 words):\")\n",
    "print(embedding_layer.embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0aab5-13cf-485b-a802-1c4b58011ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
