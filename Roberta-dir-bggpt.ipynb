{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ef8f0c-2fff-47f0-a670-213fcc41db19",
   "metadata": {},
   "source": [
    "Give me a python code for question answering using roberta model. In the model embed a context from few cyrillic pdf files in pdf_files directory, few cyrillic HTML files in html_files directory and a questions-answers.csv in csv_files directory. After this receive a question and retrieve an answer using INSAIT BGGPT 9B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc1247-15d5-4116-b07b-cf814dd37045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfplumber\n",
    "import torch\n",
    "\n",
    "# Load RoBERTa QA model and tokenizer\n",
    "model_name_roberta = \"deepset/roberta-base-squad2\"\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(model_name_roberta)\n",
    "model_roberta = AutoModelForQuestionAnswering.from_pretrained(model_name_roberta)\n",
    "qa_pipeline_roberta = pipeline(\"question-answering\", model=model_roberta, tokenizer=tokenizer_roberta)\n",
    "\n",
    "# Load the INSAIT BGGPT 9B model and tokenizer (assuming it exists on Hugging Face, if not, you'll need to adjust)\n",
    "model_name_bggpt = \"INSAIT/BGGPT-9B\"\n",
    "tokenizer_bggpt = AutoTokenizer.from_pretrained(model_name_bggpt)\n",
    "model_bggpt = AutoModelForQuestionAnswering.from_pretrained(model_name_bggpt)\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdfs(directory):\n",
    "    text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory, filename)\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Function to extract text from HTML files\n",
    "def extract_text_from_htmls(directory):\n",
    "    text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".html\") or filename.endswith(\".htm\"):\n",
    "            html_path = os.path.join(directory, filename)\n",
    "            with open(html_path, \"r\", encoding=\"utf-8\") as html_file:\n",
    "                soup = BeautifulSoup(html_file, \"html.parser\")\n",
    "                text += soup.get_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Function to extract context from CSV files\n",
    "def extract_context_from_csv(directory):\n",
    "    text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            csv_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            for _, row in df.iterrows():\n",
    "                text += f\"Q: {row['question']} A: {row['answer']}\\n\"\n",
    "    return text\n",
    "\n",
    "# Function to process context\n",
    "def preprocess_context(pdf_dir, html_dir, csv_dir):\n",
    "    pdf_context = extract_text_from_pdfs(pdf_dir)\n",
    "    html_context = extract_text_from_htmls(html_dir)\n",
    "    csv_context = extract_context_from_csv(csv_dir)\n",
    "    combined_context = pdf_context + html_context + csv_context\n",
    "    return combined_context\n",
    "\n",
    "# Function to get an answer from RoBERTa model\n",
    "def get_answer_roberta(question, context):\n",
    "    result = qa_pipeline_roberta(question=question, context=context)\n",
    "    return result\n",
    "\n",
    "# Function to get an answer from INSAIT BGGPT 9B model (this step assumes it can handle a similar format)\n",
    "def get_answer_bggpt(question, context):\n",
    "    # Using the BGGPT model for answering the question\n",
    "    inputs = tokenizer_bggpt(question, context, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_bggpt(**inputs)\n",
    "        answer = tokenizer_bggpt.decode(outputs.logits.argmax(-1), skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Directories for the files\n",
    "    pdf_dir = \"pdf_files\"\n",
    "    html_dir = \"html_files\"\n",
    "    csv_dir = \"csv_files\"\n",
    "\n",
    "    # Process and combine the context from files\n",
    "    print(\"Extracting and combining context from files...\")\n",
    "    context = preprocess_context(pdf_dir, html_dir, csv_dir)\n",
    "\n",
    "    # Start the question-answering loop\n",
    "    print(\"\\nContext loaded. You can now ask questions.\")\n",
    "    while True:\n",
    "        question = input(\"Enter your question (or type 'exit' to quit): \").strip()\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Get answer using RoBERTa model first for context-based extraction\n",
    "        print(\"\\nAnswering using RoBERTa model for context extraction...\")\n",
    "        roberta_answer = get_answer_roberta(question, context)\n",
    "        print(f\"RoBERTa Answer: {roberta_answer['answer']}\\nConfidence: {roberta_answer['score']:.2f}\")\n",
    "        \n",
    "        # Get answer using INSAIT BGGPT 9B model for detailed answering\n",
    "        print(\"\\nAnswering using INSAIT BGGPT 9B model...\")\n",
    "        bggpt_answer = get_answer_bggpt(question, context)\n",
    "        print(f\"BGGPT 9B Answer: {bggpt_answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122bb0c-1df5-4edf-badb-1ab5f7210ce4",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "#### Context Extraction:\n",
    "\n",
    "The code extracts context from files located in the specified directories:\n",
    "PDF files are processed using the pdfplumber library to extract text.\n",
    "HTML files are processed using BeautifulSoup to get plain text.\n",
    "CSV files are read with pandas and formatted for question-answer extraction.\n",
    "RoBERTa QA Model:\n",
    "\n",
    "The deepset/roberta-base-squad2 model is used to extract context-based answers. It operates by finding the most relevant span of text within the provided context.\n",
    "\n",
    "#### INSAIT BGGPT 9B Model:\n",
    "\n",
    "After extracting context, the script uses the INSAIT BGGPT 9B model (which assumes it exists or is available via Hugging Face). This model is used to provide a more advanced, ChatGPT-style response after the context extraction.\n",
    "\n",
    "#### Question-Answering Loop:\n",
    "\n",
    "The user is prompted to enter a question, and the system first answers using the RoBERTa model, followed by answering with the BGGPT 9B model.\n",
    "\n",
    "##### Notes:\n",
    "BGGPT 9B: This code assumes that INSAIT BGGPT 9B exists on Hugging Face and can be accessed using the standard model loading process. If the model is not available or requires specific API access, you may need to adapt the model loading part accordingly.\n",
    "\n",
    "Performance Considerations: RoBERTa is used first for quick context extraction, followed by a more sophisticated answer using BGGPT 9B. Make sure you have adequate system resources for running large models like BGGPT 9B, especially if they are not pre-optimized for inference.\n",
    "\n",
    "##### Setup Requirements:\n",
    "###### Libraries:\n",
    "\n",
    "pip install transformers pandas bs4 pdfplumber torch\n",
    "Directory Structure:\n",
    "\n",
    "Ensure that the pdf_files, html_files, and csv_files directories exist and contain the relevant files.\n",
    "\n",
    "###### Running the Script: Execute the script:\n",
    "\n",
    "#### python question_answering_with_roberta_bggpt.py\n",
    "\n",
    "This should provide you with a framework that extracts context from multiple sources and answers questions using both RoBERTa and the INSAIT BGGPT 9B model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
